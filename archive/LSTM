code for LSTM
import numpy as np
from sklearn.preprocessing import MinMaxScaler
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
import matplotlib.pyplot as plt
# Load your data, skipping the first line if it's a header
with open("C:\\Stocks\\a.us.txt", "r", encoding='utf-8') as f:
    lines = f.readlines()
    data = lines[1:]  # This skips the first line

# Process your data
# Assuming each line after the header is a comma-separated list of numbers:
processed_data = []
for line in data:
    if line.strip():  # This checks if the line is not empty
        values = line.strip().split(',')
        # Depending on which column you need, convert it to float. For example, the 'Close' price:
        close_price = float(values[4])  # Index 4 assuming 'Close' is the fifth column
        processed_data.append(close_price)

# Now, 'processed_data' is a list of floats of the 'Close' prices
data_array = np.array(processed_data).reshape(-1, 1)

# Normalize the data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data_array.reshape(-1, 1))

# Creating sequences for LSTM input
def create_sequences(dataset, time_step):
    X, y = [], []
    for i in range(len(dataset) - time_step - 1):
        a = dataset[i:(i + time_step), 0]
        X.append(a)
        y.append(dataset[i + time_step, 0])
    return np.array(X), np.array(y)

time_step = 60  # This is an example, adjust based on your data
X, y = create_sequences(scaled_data, time_step)

# Reshape input to be [samples, time steps, features] which is required for LSTM
X = np.reshape(X, (X.shape[0], X.shape[1], 1))

# Splitting data into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# After X_train is defined
time_step = X_train.shape[1]

# LSTM Model Definition
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(time_step, X_train.shape[2])))
model.add(Dropout(0.2))

model.add(LSTM(units=50, return_sequences=False)) # Set return_sequences to False here
model.add(Dropout(0.2))

# Adding a dense layer with 1 unit for output
model.add(Dense(units=1))
# Compile, summarize, and fit the model
model.compile(optimizer='adam', loss='mean_squared_error')
model.summary()
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=1)

# Plotting
import matplotlib.pyplot as plt
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Test Loss')
plt.legend()
